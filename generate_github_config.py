#!/usr/bin/env python3
"""
ä¸ºGitHub Actionsç”Ÿæˆé…ç½®æ–‡ä»¶
"""

import argparse
import json
from datetime import datetime
from user_config import UserConfig, save_user_config


def get_preset_configs():
    """è·å–é¢„è®¾é…ç½®"""
    return {
        "embodied_ai": {
            "search_keywords": ["embodied", "embodied AI", "robotics", "embodied intelligence"],
            "research_categories": ["cs.AI", "cs.RO", "cs.CV", "cs.LG"],
            "description": "å…·èº«æ™ºèƒ½ç ”ç©¶"
        },
        "multimodal_learning": {
            "search_keywords": ["multimodal", "vision-language", "CLIP", "cross-modal", "VLM"],
            "research_categories": ["cs.CV", "cs.CL", "cs.LG", "cs.AI"],
            "description": "å¤šæ¨¡æ€å­¦ä¹ "
        },
        "large_language_models": {
            "search_keywords": ["large language model", "LLM", "transformer", "GPT", "BERT"],
            "research_categories": ["cs.CL", "cs.AI", "cs.LG"],
            "description": "å¤§è¯­è¨€æ¨¡å‹"
        },
        "computer_vision": {
            "search_keywords": ["computer vision", "image processing", "object detection", "segmentation"],
            "research_categories": ["cs.CV", "cs.AI", "cs.LG"],
            "description": "è®¡ç®—æœºè§†è§‰"
        },
        "reinforcement_learning": {
            "search_keywords": ["reinforcement learning", "RL", "agent", "policy learning"],
            "research_categories": ["cs.LG", "cs.AI", "cs.RO"],
            "description": "å¼ºåŒ–å­¦ä¹ "
        },
        "recent_trends": {
            "search_keywords": ["AI", "machine learning", "deep learning", "neural network"],
            "research_categories": ["cs.AI", "cs.LG", "cs.CV", "cs.CL"],
            "description": "æœ€æ–°AIè¶‹åŠ¿"
        }
    }


def parse_list_input(input_str):
    """è§£æé€—å·åˆ†éš”çš„è¾“å…¥"""
    if not input_str:
        return []
    return [item.strip() for item in input_str.split(',') if item.strip()]


def main():
    parser = argparse.ArgumentParser(description='ä¸ºGitHub Actionsç”Ÿæˆé…ç½®')
    parser.add_argument('--keywords', type=str, help='æ£€ç´¢å…³é”®è¯ (é€—å·åˆ†éš”)')
    parser.add_argument('--categories', type=str, help='ç ”ç©¶é¢†åŸŸ (é€—å·åˆ†éš”)')
    parser.add_argument('--start-date', type=str, help='å¼€å§‹æ—¥æœŸ')
    parser.add_argument('--end-date', type=str, help='ç»“æŸæ—¥æœŸ')
    parser.add_argument('--max-papers', type=int, default=50, help='æœ€å¤§è®ºæ–‡æ•°é‡')
    parser.add_argument('--preset', type=str, default='custom', help='é¢„è®¾é…ç½®')
    
    args = parser.parse_args()
    
    # è·å–é¢„è®¾é…ç½®
    presets = get_preset_configs()
    
    if args.preset != 'custom' and args.preset in presets:
        # ä½¿ç”¨é¢„è®¾é…ç½®
        preset = presets[args.preset]
        config = UserConfig(
            search_keywords=preset["search_keywords"],
            research_categories=preset["research_categories"],
            start_date=args.start_date or "2024-01-01",
            end_date=args.end_date or "2024-12-31",
            max_papers=args.max_papers,
            custom_task_categories={},
            use_default_categories=True,
            include_author_affiliations=True,
            output_format="csv"
        )
        print(f"âœ… ä½¿ç”¨é¢„è®¾é…ç½®: {preset['description']}")
    else:
        # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
        config = UserConfig(
            search_keywords=parse_list_input(args.keywords),
            research_categories=parse_list_input(args.categories),
            start_date=args.start_date or "2024-01-01",
            end_date=args.end_date or "2024-12-31",
            max_papers=args.max_papers,
            custom_task_categories={},
            use_default_categories=True,
            include_author_affiliations=True,
            output_format="csv"
        )
        print("âœ… ä½¿ç”¨è‡ªå®šä¹‰é…ç½®")
    
    # ä¿å­˜é…ç½®
    save_user_config(config)
    
    # è¾“å‡ºé…ç½®ä¿¡æ¯
    print(f"ğŸ” æ£€ç´¢å…³é”®è¯: {', '.join(config.search_keywords)}")
    print(f"ğŸ·ï¸ ç ”ç©¶é¢†åŸŸ: {', '.join(config.research_categories)}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {config.start_date} åˆ° {config.end_date}")
    print(f"ğŸ“Š æœ€å¤§è®ºæ–‡æ•°: {config.max_papers}")
    
    # ç”Ÿæˆè¿è¡Œä¿¡æ¯æ–‡ä»¶
    run_info = {
        "timestamp": datetime.now().isoformat(),
        "config": {
            "search_keywords": config.search_keywords,
            "research_categories": config.research_categories,
            "start_date": config.start_date,
            "end_date": config.end_date,
            "max_papers": config.max_papers
        },
        "preset_used": args.preset if args.preset != 'custom' else None
    }
    
    with open('output/run_info.json', 'w', encoding='utf-8') as f:
        json.dump(run_info, f, ensure_ascii=False, indent=2)
    
    print("âœ… é…ç½®ç”Ÿæˆå®Œæˆ")


if __name__ == "__main__":
    main()