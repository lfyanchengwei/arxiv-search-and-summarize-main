#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬ - å¢å¼ºç‰ˆå­¦æœ¯è®ºæ–‡åˆ†æç³»ç»Ÿ
æä¾›é¢„è®¾é…ç½®çš„å¿«é€Ÿå¯åŠ¨é€‰é¡¹
"""

import os
import sys
import argparse
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from user_config import UserConfig, save_user_config
from loguru import logger


def get_preset_configs():
    """è·å–é¢„è®¾é…ç½®"""
    now = datetime.now()
    past_year = (now - timedelta(days=365)).strftime("%Y-%m-%d")
    current_date = now.strftime("%Y-%m-%d")
    
    return {
        "1": {
            "name": "å…·èº«æ™ºèƒ½ç ”ç©¶ (Embodied AI)",
            "description": "æœç´¢å…·èº«æ™ºèƒ½ã€æœºå™¨äººå­¦ç›¸å…³è®ºæ–‡",
            "config": UserConfig(
                search_keywords=["embodied", "embodied AI", "robotics", "embodied intelligence"],
                research_categories=["cs.AI", "cs.RO", "cs.CV", "cs.LG"],
                start_date="2024-01-01",
                end_date="2024-12-31",
                max_papers=50,
                custom_task_categories={},
                use_default_categories=True,
                include_author_affiliations=True,
                output_format="csv"
            )
        },
        "2": {
            "name": "å¤šæ¨¡æ€å­¦ä¹  (Multimodal Learning)",
            "description": "æœç´¢å¤šæ¨¡æ€ã€è§†è§‰-è¯­è¨€æ¨¡å‹ç›¸å…³è®ºæ–‡",
            "config": UserConfig(
                search_keywords=["multimodal", "vision-language", "CLIP", "cross-modal", "VLM"],
                research_categories=["cs.CV", "cs.CL", "cs.LG", "cs.AI"],
                start_date="2024-01-01",
                end_date="2024-12-31",
                max_papers=50,
                custom_task_categories={},
                use_default_categories=True,
                include_author_affiliations=True,
                output_format="csv"
            )
        },
        "3": {
            "name": "å¤§è¯­è¨€æ¨¡å‹ (Large Language Models)",
            "description": "æœç´¢å¤§è¯­è¨€æ¨¡å‹ã€Transformerç›¸å…³è®ºæ–‡",
            "config": UserConfig(
                search_keywords=["large language model", "LLM", "transformer", "GPT", "BERT"],
                research_categories=["cs.CL", "cs.AI", "cs.LG"],
                start_date="2024-01-01",
                end_date="2024-12-31",
                max_papers=50,
                custom_task_categories={},
                use_default_categories=True,
                include_author_affiliations=True,
                output_format="csv"
            )
        },
        "4": {
            "name": "è®¡ç®—æœºè§†è§‰ (Computer Vision)",
            "description": "æœç´¢è®¡ç®—æœºè§†è§‰ã€å›¾åƒå¤„ç†ç›¸å…³è®ºæ–‡",
            "config": UserConfig(
                search_keywords=["computer vision", "image processing", "object detection", "segmentation"],
                research_categories=["cs.CV", "cs.AI", "cs.LG"],
                start_date="2024-01-01",
                end_date="2024-12-31",
                max_papers=50,
                custom_task_categories={},
                use_default_categories=True,
                include_author_affiliations=True,
                output_format="csv"
            )
        },
        "5": {
            "name": "å¼ºåŒ–å­¦ä¹  (Reinforcement Learning)",
            "description": "æœç´¢å¼ºåŒ–å­¦ä¹ ã€æ™ºèƒ½ä½“ç›¸å…³è®ºæ–‡",
            "config": UserConfig(
                search_keywords=["reinforcement learning", "RL", "agent", "policy learning"],
                research_categories=["cs.LG", "cs.AI", "cs.RO"],
                start_date="2024-01-01",
                end_date="2024-12-31",
                max_papers=50,
                custom_task_categories={},
                use_default_categories=True,
                include_author_affiliations=True,
                output_format="csv"
            )
        },
        "6": {
            "name": "æœ€æ–°çƒ­ç‚¹ (Recent Trends)",
            "description": "æœç´¢æœ€è¿‘3ä¸ªæœˆçš„AIçƒ­ç‚¹è®ºæ–‡",
            "config": UserConfig(
                search_keywords=["AI", "machine learning", "deep learning", "neural network"],
                research_categories=["cs.AI", "cs.LG", "cs.CV", "cs.CL"],
                start_date=(now - timedelta(days=90)).strftime("%Y-%m-%d"),
                end_date=current_date,
                max_papers=30,
                custom_task_categories={},
                use_default_categories=True,
                include_author_affiliations=True,
                output_format="csv"
            )
        }
    }


def display_presets():
    """æ˜¾ç¤ºé¢„è®¾é…ç½®é€‰é¡¹"""
    presets = get_preset_configs()
    
    print("ğŸš€ å¢å¼ºç‰ˆå­¦æœ¯è®ºæ–‡åˆ†æç³»ç»Ÿ - å¿«é€Ÿå¯åŠ¨")
    print("=" * 60)
    print("è¯·é€‰æ‹©é¢„è®¾é…ç½®ï¼š\n")
    
    for key, preset in presets.items():
        config = preset["config"]
        print(f"{key}. {preset['name']}")
        print(f"   ğŸ“ {preset['description']}")
        print(f"   ğŸ” æ£€ç´¢è¯: {', '.join(config.search_keywords[:3])}{'...' if len(config.search_keywords) > 3 else ''}")
        print(f"   ğŸ“… æ—¶é—´èŒƒå›´: {config.start_date} åˆ° {config.end_date}")
        print(f"   ğŸ“Š æœ€å¤§è®ºæ–‡æ•°: {config.max_papers}")
        print()
    
    print("7. è‡ªå®šä¹‰é…ç½® (è¿›å…¥äº¤äº’å¼é…ç½®æ¨¡å¼)")
    print("0. é€€å‡º")
    print("=" * 60)


def get_user_choice():
    """è·å–ç”¨æˆ·é€‰æ‹©"""
    while True:
        choice = input("è¯·è¾“å…¥é€‰é¡¹ç¼–å· (0-7): ").strip()
        if choice in ['0', '1', '2', '3', '4', '5', '6', '7']:
            return choice
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-7 ä¹‹é—´çš„æ•°å­—")


def confirm_config(preset_name, config):
    """ç¡®è®¤é…ç½®ä¿¡æ¯"""
    print(f"\nğŸ“‹ å·²é€‰æ‹©é…ç½®: {preset_name}")
    print("-" * 40)
    print(f"ğŸ” æ£€ç´¢è¯: {', '.join(config.search_keywords)}")
    print(f"ğŸ·ï¸ ç ”ç©¶é¢†åŸŸ: {', '.join(config.research_categories)}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {config.start_date} åˆ° {config.end_date}")
    print(f"ğŸ“Š æœ€å¤§è®ºæ–‡æ•°: {config.max_papers}")
    print(f"ğŸ¯ ä»»åŠ¡åˆ†ç±»: {'é»˜è®¤åˆ†ç±»' if config.use_default_categories else 'è‡ªå®šä¹‰åˆ†ç±»'}")
    print("-" * 40)
    
    confirm = input("ç¡®è®¤ä½¿ç”¨æ­¤é…ç½®ï¼Ÿ(y/n): ").lower().strip()
    return confirm in ['y', 'yes', 'æ˜¯', 'ç¡®è®¤']


def run_analysis(api_key, config, output_dir="output"):
    """è¿è¡Œè®ºæ–‡åˆ†æ"""
    # ä¿å­˜é…ç½®
    save_user_config(config)
    print("âœ… é…ç½®å·²ä¿å­˜")
    
    # æ„å»ºå‘½ä»¤è¡Œå‚æ•°
    cmd_args = [
        "python", "enhanced_main.py",
        "--openai_api_key", api_key,
        "--output_dir", output_dir,
        "--skip_setup"  # è·³è¿‡äº¤äº’é…ç½®
    ]
    
    print(f"\nğŸš€ å¼€å§‹åˆ†æè®ºæ–‡...")
    print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {output_dir}")
    print("-" * 40)
    
    # æ‰§è¡Œåˆ†æ
    import subprocess
    try:
        result = subprocess.run(cmd_args, check=True, capture_output=False)
        print("\nâœ… åˆ†æå®Œæˆï¼")
        return True
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        return False
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­åˆ†æ")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¿«é€Ÿå¯åŠ¨å­¦æœ¯è®ºæ–‡åˆ†æ')
    parser.add_argument('--api_key', type=str, help='OpenAI APIå¯†é’¥')
    parser.add_argument('--output_dir', type=str, default='output', help='è¾“å‡ºç›®å½•')
    args = parser.parse_args()
    
    # è·å–APIå¯†é’¥
    api_key = args.api_key or os.environ.get('OPENAI_API_KEY')
    if not api_key:
        print("âŒ è¯·æä¾›OpenAI APIå¯†é’¥")
        print("æ–¹æ³•1: python quick_start.py --api_key YOUR_API_KEY")
        print("æ–¹æ³•2: è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        sys.exit(1)
    
    try:
        while True:
            display_presets()
            choice = get_user_choice()
            
            if choice == '0':
                print("ğŸ‘‹ å†è§ï¼")
                break
            elif choice == '7':
                print("ğŸ”§ å¯åŠ¨äº¤äº’å¼é…ç½®æ¨¡å¼...")
                # è¿è¡Œå®Œæ•´çš„äº¤äº’å¼é…ç½®
                cmd_args = ["python", "enhanced_main.py", "--openai_api_key", api_key]
                subprocess.run(cmd_args)
                break
            else:
                # ä½¿ç”¨é¢„è®¾é…ç½®
                presets = get_preset_configs()
                preset = presets[choice]
                
                if confirm_config(preset["name"], preset["config"]):
                    success = run_analysis(api_key, preset["config"], args.output_dir)
                    if success:
                        # è¯¢é—®æ˜¯å¦ç»§ç»­
                        if input("\næ˜¯å¦ç»§ç»­é€‰æ‹©å…¶ä»–é…ç½®ï¼Ÿ(y/n): ").lower().strip() not in ['y', 'yes', 'æ˜¯']:
                            break
                    else:
                        print("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")
                else:
                    print("âŒ å·²å–æ¶ˆ")
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·é€€å‡º")
    except Exception as e:
        logger.error(f"ç¨‹åºå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()